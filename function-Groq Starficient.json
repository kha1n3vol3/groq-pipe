[{"id":"1cfb94d8-c84c-4518-8072-f7309f7c0437","userId":"2eef6d8b-f403-4742-a835-ba30e0157277","function":{"id":"groq_starficient","name":"Groq Starficient","meta":{"description":"Manifold Pipe for Groq with Kimi support.","type":"pipe","manifest":{"title":"Groq Starficient","author":"https://github.com/kha1n3vol3/groq-pipe","author_url":"https://github.com/kha1n3vol3","funding_url":"https://github.com/kha1n3vol3","version":"0.1"}},"content":"\"\"\"\ntitle: Groq Starficient\nauthor: https://github.com/kha1n3vol3/groq-pipe\nauthor_url: https://github.com/kha1n3vol3\nfunding_url: https://github.com/kha1n3vol3\nversion: 0.1\n\nThis module exports one public class – ``Pipe`` – that adapts Groq’s\nOpenAI-compatible REST API to Open WebUI’s plug-in interface.\n\nThe class\n• validates input\n• strips any WebUI-added `<prefix>.` in front of the model id\n• checks the model id against a cached allow-list (prevents 404s)\n• sends the request with automatic connection reuse\n• returns either the JSON response, an iterator of streamed bytes, or a\n  descriptive error string.\n                                       █████████████████████████\n                                      ████████████████████████\n                                     █████████████████████████\n                                    █████████████████████████\n                                   █████████████████████████\n                                  █████████████████████████\n                                 █████████████████████████\n                                █████████████████████████\n                               █████████████████████████\n                              █████████████████████████\n                             █████████████████████████\n                            █████████████████████████\n                           █████████████████████████                  ███\n                          █████████████████████████                   ████\n                         █████████████████████████                   ██████\n                        █████████████████████████                   ████████\n                        ████████████████████████                   █████████\n                       ████████████████████████                  ████████████\n                      ████████████████████████                  ██████████████\n                     █████████████████████████                 ████████████████\n                    █████████████████████████                  █████████████████\n                   █████████████████████████                  ███████████████████\n                  █████████████████████████                  █████████████████████\n                 █████████████████████████                  ███████████████████████\n                █████████████████████████                  █████████████████████████\n               █████████████████████████                    █████████████████████████\n              ████████████████████████                       █████████████████████████\n             █████████████████████████                        █████████████████████████\n            █████████████████████████                          █████████████████████████\n           █████████████████████████                            █████████████████████████\n          █████████████████████████                              █████████████████████████\n         █████████████████████████                                █████████████████████████\n        █████████████████████████                                  █████████████████████████\n       █████████████████████████                                    ████████████████████████\n      █████████████████████████                                      ████████████████████████\n     █████████████████████████                                        ████████████████████████\n    █████████████████████████                                          ████████████████████████\n   ██████████████████████████                                          █████████████████████████\n  ██████████████████████████                                            █████████████████████████\n  █████████████████████████                                              █████████████████████████\n █████████████████████████                                                █████████████████████████\n█████████████████████████                                                  █████████████████████████\n\"\"\"\n\nfrom __future__ import annotations\n\nimport logging\nimport os\nfrom typing import (\n    Any,\n    Dict,\n    Generator,\n    Iterator,\n    List,\n    Optional,\n    Union,\n)\n\nimport requests\nfrom pydantic import BaseModel, Field\n\n# ────────────────────────────────────────────────────────────────────────\n# Configuration constants\n# ────────────────────────────────────────────────────────────────────────\nAPI_BASE_URL = \"https://api.groq.com/openai/v1\"\nREQUEST_TIMEOUT = 60  # seconds\nEXCLUDE_SUBSTRINGS: tuple[str, ...] = (\"tts\", \"whisper\")  # never expose\nLOG_FORMAT = \"%(asctime)s [%(levelname)s] %(name)s: %(message)s\"\n\nlogging.basicConfig(level=logging.INFO, format=LOG_FORMAT)\nLOGGER = logging.getLogger(\"GroqPipe\")\n\n\nclass Pipe:\n    \"\"\"\n    Lightweight wrapper around Groq’s ``/chat/completions`` endpoint.\n\n    The class is instantiated once by Open WebUI and then used as a\n    long-lived object.  A ``requests.Session`` is therefore kept around for\n    TCP connection reuse.\n    \"\"\"\n\n    # ─────────────────────────── secrets / valves ──────────────────────\n    class Valves(BaseModel):\n        \"\"\"\n        Container object for secrets so WebUI can inspect the schema.\n        \"\"\"\n\n        API_KEY: str = Field(\n            default=os.getenv(\"GROQ_API_KEY\", \"\"),\n            description=\"Create / copy a key at https://console.groq.com/keys\",\n        )\n\n    # ────────────────────────────── init ───────────────────────────────\n    def __init__(self) -> None:\n        self.type = \"manifold\"\n        self.id = \"groq\"  # prefix used by Open WebUI\n        self.name = \"groq/\"\n        self.base_url = API_BASE_URL\n        self.valves = self.Valves()\n        self._session = requests.Session()\n        self._model_cache: Optional[List[str]] = None  # populated on demand\n\n    # ──────────────────────────── model list ───────────────────────────\n    @staticmethod\n    def _hardcoded_models() -> List[str]:\n        \"\"\"\n        Return a hand-curated list of models (2024-06).\n\n        Hard-coding avoids a network round-trip on every UI page load and\n        still works if Groq’s `/models` endpoint is temporarily down.\n        \"\"\"\n        return [\n            \"allam-2-7b\",\n            \"compound-beta\",\n            \"compound-beta-mini\",\n            \"deepseek-r1-distill-llama-70b\",\n            \"gemma2-9b-it\",\n            \"llama-3.1-8b-instant\",\n            \"llama-3.3-70b-versatile\",\n            \"llama3-70b-8192\",\n            \"llama3-8b-8192\",\n            \"meta-llama/llama-guard-4-12b\",\n            \"meta-llama/llama-prompt-guard-2-22m\",\n            \"meta-llama/llama-prompt-guard-2-86m\",\n            \"meta-llama/llama-4-maverick-17b-128e-instruct\",\n            \"meta-llama/llama-4-scout-17b-16e-instruct\",\n            \"mistral-saba-24b\",\n            \"moonshotai/kimi-k2-instruct\",\n            \"qwen/qwen3-32b\",\n        ]\n\n    def _fetch_models_once(self) -> List[str]:\n        \"\"\"\n        Fetch ``GET /models`` exactly once per process, cache the result.\n\n        Falls back to ``_hardcoded_models`` if the request fails.\n        Excludes any model containing a substring in ``EXCLUDE_SUBSTRINGS``.\n        \"\"\"\n        if self._model_cache is not None:\n            return self._model_cache\n\n        try:\n            LOGGER.info(\"Fetching model list from Groq …\")\n            response = self._session.get(\n                f\"{self.base_url}/models\",\n                headers={\"Authorization\": f\"Bearer {self.valves.API_KEY}\"},\n                timeout=REQUEST_TIMEOUT,\n            )\n            response.raise_for_status()\n            remote_models = [m[\"id\"] for m in response.json().get(\"data\", [])]\n            self._model_cache = [\n                m for m in remote_models if not any(x in m for x in EXCLUDE_SUBSTRINGS)\n            ]\n            LOGGER.info(\"Cached %d models from Groq.\", len(self._model_cache))\n        except Exception as exc:  # pylint: disable=broad-except\n            LOGGER.warning(\"Model refresh failed (%s); using hard-coded list.\", exc)\n            self._model_cache = [\n                m\n                for m in self._hardcoded_models()\n                if not any(x in m for x in EXCLUDE_SUBSTRINGS)\n            ]\n\n        return self._model_cache\n\n    # Public helper for Open WebUI\n    def pipes(self) -> List[Dict[str, str]]:\n        \"\"\"\n        Return the model list in Open WebUI’s expected ``[{id, name}, …]`` format.\n        \"\"\"\n        return [{\"id\": m, \"name\": m} for m in self._fetch_models_once()]\n\n    # ───────────────────────── main request ────────────────────────────\n    def pipe(\n        self,\n        body: Dict[str, Any],\n    ) -> Union[\n        str,\n        Dict[str, Any],\n        Generator[bytes, None, None],\n        Iterator[bytes],\n    ]:\n        \"\"\"\n        Execute ``POST /chat/completions``.\n\n        Parameters\n        ----------\n        body : dict\n            The request payload expected by the OpenAI API.\n\n        Returns\n        -------\n        dict | iterator | str\n            • dict: normal non-streamed response\n            • iterator / generator: when ``stream`` is ``True``\n            • str: human-readable error message\n        \"\"\"\n\n        # ---------- basic validation -----------------------------------\n        if \"model\" not in body or \"stream\" not in body:\n            return \"Error: request body must contain 'model' and 'stream'.\"\n\n        if not self.valves.API_KEY:\n            return \"Error: GROQ_API_KEY environment variable not set.\"\n\n        # ---------- strip any '<prefix>.' that WebUI adds --------------\n        if \".\" in body[\"model\"]:\n            body[\"model\"] = body[\"model\"].split(\".\", 1)[1]\n\n        model_name = body[\"model\"]\n        allowed_models = self._fetch_models_once()\n        if model_name not in allowed_models:\n            return (\n                f\"Error: model '{model_name}' is not supported.\\n\"\n                f\"Valid models: {', '.join(allowed_models)}\"\n            )\n\n        # ---------- perform request ------------------------------------\n        url = f\"{self.base_url}/chat/completions\"\n        headers = {\n            \"Authorization\": f\"Bearer {self.valves.API_KEY}\",\n            \"Content-Type\": \"application/json\",\n        }\n\n        try:\n            response = self._session.post(\n                url=url,\n                json=body,\n                headers=headers,\n                stream=bool(body[\"stream\"]),\n                timeout=REQUEST_TIMEOUT,\n            )\n            response.raise_for_status()\n            return response.iter_lines() if body[\"stream\"] else response.json()\n\n        except requests.exceptions.HTTPError as exc:\n            msg = (\n                f\"HTTP {response.status_code} calling {url}: {exc}\\n\" f\"{response.text}\"\n            )\n            if response.status_code == 404:\n                msg += \"\\n(404 usually means an unknown model id.)\"\n            return msg\n\n        except Exception as exc:  # pylint: disable=broad-except\n            return f\"Unhandled error: {exc}\"\n\n\n# ───────────────────────────── demo / self-test ─────────────────────────────\nif __name__ == \"__main__\":\n    pipe = Pipe()\n\n    demo_request = {\n        \"model\": \"groq_new.moonshotai/kimi-k2-instruct\",  # intentional prefix\n        \"messages\": [{\"role\": \"user\", \"content\": \"Hello from demo!\"}],\n        \"stream\": False,\n    }\n\n    print(\"Sending demo request …\")\n    result = pipe.pipe(demo_request)\n    print(\"Result:\\n\", result)\n"},"info":{"body":"Supports moonshotai/Kimi K2 1T 128k !"},"downloads":23,"upvotes":0,"downvotes":0,"updatedAt":1752770259,"createdAt":1752769638,"user":{"id":"2eef6d8b-f403-4742-a835-ba30e0157277","username":"khunt","name":"","createdAt":1734798144,"role":null,"verified":false}}]